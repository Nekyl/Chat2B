# Chat 2B 

Um front-end de chat, 100% client-side, para interagir com as APIs do Google Gemini e inst√¢ncias locais do Ollama.

O projeto foi criado com uma persona de IA customizada: espirituosa, sarc√°stica e divertida, visando uma experi√™ncia de conversa√ß√£o mais natural e envolvente do que a de assistentes tradicionais.

## ‚ú® Features

*   **Dual Backend: Gemini & Ollama:** Conecte-se √† API do **Google Gemini** ou a qualquer inst√¢ncia local/remota do **Ollama**, com suporte para endpoints customizados (`http/https`).
*   **Suporte a Vision (Multimodal):** Envie imagens anexando arquivos ou colando diretamente no chat ao usar modelos Gemini com capacidade de vis√£o.
*   **Progressive Web App (PWA):** Instale o chat como um aplicativo de desktop ou mobile para acesso r√°pido e uma experi√™ncia mais nativa.
*   **Renderiza√ß√£o de C√≥digo Avan√ßada:** Suporte a Markdown, syntax highlighting e um bot√£o para copiar o conte√∫do dos blocos de c√≥digo.
*   **Gerenciamento Completo de Chats:** Hist√≥rico salvo localmente, com funcionalidades para criar, renomear, exportar e realizar buscas em todas as conversas.
*   **IA Customiz√°vel:** Altere o Prompt do Sistema e a Temperatura do modelo diretamente nas configura√ß√µes para ajustar a persona da IA.

## üöÄ Recommended Models

Para obter a melhor experi√™ncia e extrair o m√°ximo da persona customizada, o uso dos seguintes modelos √© altamente recomendado:

*   **Gemini 2.5 Flash** ou **Gemini 2.5 Pro**

## ‚öôÔ∏è Getting Started

Este projeto √© 100% client-side, sem necessidade de build steps.

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/Nekyl/2B-Chat.git
    ```

2.  **Abra o `index.html`:**
    *   A maneira mais simples √© usar uma extens√£o como o **Live Server** no VS Code para servir os arquivos localmente.
    *   Alternativamente, abrir o `index.html` diretamente no navegador deve funcionar.

### Configuration

Ao abrir o aplicativo, configure sua fonte de API no campo de texto superior:

*   **Para usar o Gemini:**
    1.  Digite `gemini` no campo de fonte.
    2.  Na primeira vez que enviar uma mensagem, o aplicativo solicitar√° sua **Chave de API do Google AI Studio**. Ela ser√° salva localmente no seu navegador.

*   **Para usar Ollama:**
    1.  Certifique-se de que sua inst√¢ncia do Ollama est√° em execu√ß√£o.
    2.  Digite `ollama` para usar o endere√ßo padr√£o (`http://localhost:11434`) ou insira a URL completa do seu servidor Ollama.
